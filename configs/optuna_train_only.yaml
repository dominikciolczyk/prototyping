# MIT License
# 
# Copyright (c) Dominik Cio≈Çczyk 2025
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# 

# environment configuration
settings:
  docker:
    required_integrations:
      - aws
      - evidently
      - kubeflow
      - kubernetes
      - mlflow
      - sklearn
      - slack

# configuration of steps  
steps:
  promote_with_metric_compare:
    parameters:
      mlflow_model_name: cloud-resource-prediction
  notify_on_success:
    parameters:
      notify_on_success: False

# configuration of the Model Control Plane
model:
  name: cloud-resource-prediction
  license: mit
  description: cloud-resource-prediction E2E Batch Use Case
  audience: All ZenML users
  use_cases: |
    The cloud-resource-prediction project demonstrates how the most important steps of 
    the ML Production Lifecycle can be implemented in a reusable way remaining 
    agnostic to the underlying infrastructure, and shows how to integrate them together 
    into pipelines for Training and Batch Inference purposes.
  ethics: No impact.
  tags:
  - e2e
  - batch
  - from template
  - ZenML delivered

# pipeline level extra configurations
extra:
  notify_on_failure: True
# pipeline level parameters
parameters:
  raw_dir: data/raw/
  zip_path: data/Dane - Polcom.zip
  raw_polcom_2022_dir: data/raw/Dane - Polcom/2022/AGH2022/
  raw_polcom_2020_dir: data/raw/Dane - Polcom/2020/
  cleaned_polcom_dir: data/cleaned/Dane - Polcom/
  cleaned_polcom_2022_dir: data/cleaned/Dane - Polcom/2022/
  cleaned_polcom_2020_dir: data/cleaned/Dane - Polcom/2020/
  data_granularity: M
  load_2022_data: True
  load_2020_data: True
  recreate_dataset: False
  val_size: 0.15
  test_size: 0.15
  online_size: 0.15
  seed: 42
  selected_columns:
    - CPU_USAGE_MHZ
    - NODE_1_DISK_IO_RATE_KBPS
    - NODE_1_NETWORK_TR_KBPS
  model_input_seq_len: 24
  model_forecast_horizon: 24
  make_plots: False
  batch: 64
  cnn_channels: [ 64, 128, 256, 512 ]
  kernels: [ 3, 5, 7, 9 ]
  hidden_lstm: 256
  lstm_layers: 1
  dropout_rate: 0.1
  alpha: 10
  beta: 3.0
  lr: 0.001
  epochs: 50
  early_stop_epochs: 15